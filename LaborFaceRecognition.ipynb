{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./imge/GLODON.png\" alt=\"广联达\" style=\"width: 500px;\"/></center>\n",
    "\n",
    "## AI劳务人脸识别\n",
    "\n",
    "@  公司名称：广联达股份有限公司<br>\n",
    "@  文件名：3.AI劳务人脸识别.ipynb <br>\n",
    "@  版本：V1.0 <br>\n",
    "@  author: glodon.com<br>\n",
    "@  说明：学习AI人脸识别的原理过程<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本节内容主要为基于Dlib来实现人脸身份识别；\n",
    "\n",
    "1.安装依赖包\n",
    "\n",
    "sudo apt-get update\n",
    "\n",
    "sudo apt-get install cmake libopenblas-dev liblapack-dev libjpeg-dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.下载dlib之前，需要一个交换文件，由于nano的内存只有4G，编译过程中需要用到交换文件；\n",
    "\n",
    "git clone https://github.com/JetsonHacksNano/installSwapfile\n",
    "\n",
    "cd installSwapfile\n",
    "\n",
    "./installSwapfile.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.下载Dlib安装包，解压\n",
    "\n",
    "wget http://dlib.net/files/dlib-19.17.tar.bz2\n",
    "\n",
    "tar jxvf dlib-19.17.tar.bz2\n",
    "\n",
    "cd dlib-19.17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.需要对源代码中的一行代码进行修改，使得适配于Jetson Nano\n",
    "\n",
    "找到如下目录：/dlib-19.17/dlib/cuda/cudnn_dlibapi.cpp\n",
    "\n",
    "注释下面代码：\n",
    "\n",
    "//forward_algo = forward_best_algo;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.安装dlib\n",
    "\n",
    "cd ..\n",
    "\n",
    "cd dlib-19.17\n",
    "\n",
    "sudo python3 setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.安装face_recognition库\n",
    "\n",
    "sudo pip3 install face_recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.人脸识别库-检测人脸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线程函数操作库\n",
    "import threading # 线程\n",
    "import ctypes\n",
    "import inspect\n",
    "\n",
    "# 线程结束代码\n",
    "def _async_raise(tid, exctype):\n",
    "    tid = ctypes.c_long(tid)\n",
    "    if not inspect.isclass(exctype):\n",
    "        exctype = type(exctype)\n",
    "    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "    if res == 0:\n",
    "        raise ValueError(\"invalid thread id\")\n",
    "    elif res != 1:\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "        raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "        \n",
    "def stop_thread(thread):\n",
    "    _async_raise(thread.ident, SystemExit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3efca121e841ff86b2f706c64547b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入显示控件的依赖库\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 创建显示原始图片的控件\n",
    "origin_imge = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(origin_imge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9a4308adac4f999832b12d9b852aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示检测结果的控件\n",
    "face_imge = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(face_imge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(136, 225, 226, 135)]\n"
     ]
    }
   ],
   "source": [
    "# 输入图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "# 如：/home/eternity/Desktop/test/*.jpg\n",
    "image=face_recognition.load_image_file('./images/face/unknown/u14.png')\n",
    "origin_imge.value = bgr8_to_jpeg(cv2.cvtColor(image,cv2.COLOR_RGB2BGR))\n",
    "face_locations=face_recognition.face_locations(image)\n",
    "print(face_locations)\n",
    "image=cv2.cvtColor(image,cv2.COLOR_RGB2BGR)\n",
    "for(row1,col1,row2,col2) in face_locations:\n",
    "    # 画框\n",
    "    cv2.rectangle(image,(col1,row1),(col2,row2),(0,0,255),2)\n",
    "face_imge.value = bgr8_to_jpeg(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.人脸身份识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e139a7a015c417890af8fa8efb29abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入显示控件的依赖库\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 创建显示添加的第一张人脸库图片的控件区域\n",
    "feature_imge1 = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(feature_imge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "732967de9ddc45a58712f57f991692b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示添加的第二张人脸库图片的控件区域\n",
    "feature_imge2 = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(feature_imge2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375a6fe1f4c5468cb263fa92c996762e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示添加的第三张人脸库图片的控件区域\n",
    "feature_imge3 = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(feature_imge3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5081af29b04b5b9e4a32f2ef750eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示添加的第四张人脸库图片的控件区域\n",
    "feature_imge4 = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(feature_imge4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222a1b5a381149b5aad90e554b9ab7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示待识别人脸图片的控件区域\n",
    "query_imge = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(query_imge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自己定义自己的人脸库时，需要建立文件，添加一定数量的人脸数据，作为人脸底库\n",
    "#下方代码中，添加了4个人的人脸数据，作为底库\n",
    "# 注意：下面代码中涉及到的主要处理函数，如face_recognition.face_encodings，face_recognition.compare_faces等，均是调用了\n",
    "# face_recognition识别库，具体有关函数的说明可查看face_recognition官方说明，https://github.com/ageitgey/face_recognition；\n",
    "\n",
    "# 特征库图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "# 如：/home/eternity/Desktop/test/*.jpg\n",
    "donFace=face_recognition.load_image_file('./images/face/known/Donald Trump.jpg')# 输入图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "feature_imge1.value = bgr8_to_jpeg(cv2.cvtColor(donFace,cv2.COLOR_RGB2BGR))\n",
    "donEncode = face_recognition.face_encodings(donFace)[0]\n",
    "\n",
    "nancyFace=face_recognition.load_image_file('./images/face/known/Nancy Pelosi.jpg')# 输入图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "feature_imge2.value = bgr8_to_jpeg(cv2.cvtColor(nancyFace,cv2.COLOR_RGB2BGR))\n",
    "nancyEncode = face_recognition.face_encodings(nancyFace)[0]\n",
    "\n",
    "penceFace=face_recognition.load_image_file('./images/face/known/Mike Pence.jpg')# 输入图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "feature_imge3.value = bgr8_to_jpeg(cv2.cvtColor(penceFace,cv2.COLOR_RGB2BGR))\n",
    "penceEncode = face_recognition.face_encodings(penceFace)[0]\n",
    "\n",
    "weijunFace=face_recognition.load_image_file('./images/face/known/sunweijun.jpg')# 输入图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "feature_imge4.value = bgr8_to_jpeg(cv2.cvtColor(weijunFace,cv2.COLOR_RGB2BGR))\n",
    "weijunEncode = face_recognition.face_encodings(weijunFace)[0]\n",
    "\n",
    "Encodings=[donEncode,nancyEncode,penceEncode,weijunEncode]\n",
    "Names=['The Donald','Nancy Pelosi','Mike Pence','sunweijun'] # 人脸库中四个人的名称\n",
    "\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# 待匹配的未知人脸\n",
    "testImage=face_recognition.load_image_file('./images/face/unknown/u16.png')# 输入图片路径，这里可替换成自己的图片目录路径，使用绝对路径即可\n",
    "# 如：/home/eternity/Desktop/test/*.jpg\n",
    "\n",
    "facePositions=face_recognition.face_locations(testImage)\n",
    "allEncodings=face_recognition.face_encodings(testImage,facePositions)\n",
    "\n",
    "testImage=cv2.cvtColor(testImage,cv2.COLOR_RGB2BGR)\n",
    "query_imge.value = bgr8_to_jpeg(testImage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc843bf007a4eb08c800e78a8e8626f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示人脸匹配结果的控件区域\n",
    "face_imge1 = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(face_imge1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (top,right,bottom,left),face_encoding in zip(facePositions,allEncodings):\n",
    "    name='Unknown Person'\n",
    "    matches=face_recognition.compare_faces(Encodings,face_encoding)\n",
    "    if True in matches:\n",
    "        first_match_index=matches.index(True)\n",
    "        name=Names[first_match_index]\n",
    "    # 画框\n",
    "    cv2.rectangle(testImage,(left,top),(right,bottom),(0,0,255),2)\n",
    "    # 写人脸对应的name到图片\n",
    "    cv2.putText(testImage,name,(left,top-6),font,.75,(0,255,255),2)\n",
    "face_imge1.value = bgr8_to_jpeg(testImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.通过摄像头进行面部身份识别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 该部分实验内容注意事项：\n",
    "\n",
    "1.一个cell一个cell的执行，不可run all，因为后面会涉及到关闭摄像头的程序代码；\n",
    "\n",
    "2.请按照最后一个cell中的提示，在结束退出实验时，请务必正确关闭摄像头，切记！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2.0\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "import cv2\n",
    "import os\n",
    "print(cv2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db1fe4ea3e8046a78645d3d45357baa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 导入显示控件的依赖库\n",
    "from jetcam.utils import bgr8_to_jpeg\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# 创建显示特征库人脸的控件区域\n",
    "feature_imge = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(feature_imge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sunweijun.jpg', 'zhanghan.jpg']\n",
      "./images/face/known2/sunweijun.jpg\n",
      "sunweijun\n",
      "./images/face/known2/zhanghan.jpg\n",
      "zhanghan\n",
      "['sunweijun', 'zhanghan']\n"
     ]
    }
   ],
   "source": [
    "# Extract feature,and Build face feature database\n",
    "Encodings=[]\n",
    "Names=[]\n",
    "\n",
    "# 在识别人脸之前，需要先提取人脸库特征\n",
    "# 为了教学快速体验，这里只添加了2张人脸到人脸库，可以自定义数量\n",
    "image_dir='./images/face/known2' # 这里是人脸特征底库的图片路径，同样可以自定义自己的特征库，可以添加自己的人脸数据，替换成自己的绝对路径即可\n",
    "# 如：/home/eternity/Desktop/test/\n",
    "for root,dirs,files in os.walk(image_dir):\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        print(path)\n",
    "        name=os.path.splitext(file)[0]\n",
    "        print(name)\n",
    "        person=face_recognition.load_image_file(path)\n",
    "        feature_imge.value = bgr8_to_jpeg(cv2.cvtColor(person,cv2.COLOR_RGB2BGR))\n",
    "        encoding=face_recognition.face_encodings(person)[0]\n",
    "        Encodings.append(encoding)\n",
    "        Names.append(name)\n",
    "print(Names)\n",
    "\n",
    "font=cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 线程函数操作库\n",
    "import threading # 线程\n",
    "import ctypes\n",
    "import inspect\n",
    "\n",
    "# 线程结束代码\n",
    "def _async_raise(tid, exctype):\n",
    "    tid = ctypes.c_long(tid)\n",
    "    if not inspect.isclass(exctype):\n",
    "        exctype = type(exctype)\n",
    "    res = ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, ctypes.py_object(exctype))\n",
    "    if res == 0:\n",
    "        raise ValueError(\"invalid thread id\")\n",
    "    elif res != 1:\n",
    "        ctypes.pythonapi.PyThreadState_SetAsyncExc(tid, None)\n",
    "        raise SystemError(\"PyThreadState_SetAsyncExc failed\")\n",
    "        \n",
    "def stop_thread(thread):\n",
    "    _async_raise(thread.ident, SystemExit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f023319ee508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Uncomment These next Two Line for Pi Camera\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcamSet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nvarguscamerasrc !  video/x-raw(memory:NVMM), width=3264, height=2464, format=NV12, framerate=21/1 ! nvvidconv flip-method='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m' ! video/x-raw, width='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', height='\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m', format=BGRx ! videoconvert ! video/x-raw, format=BGR ! appsink'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcap\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcamSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "dispW=480\n",
    "dispH=320\n",
    "flip=4\n",
    "#Uncomment These next Two Line for Pi Camera\n",
    "camSet='nvarguscamerasrc !  video/x-raw(memory:NVMM), width=3264, height=2464, format=NV12, framerate=21/1 ! nvvidconv flip-method='+str(flip)+' ! video/x-raw, width='+str(dispW)+', height='+str(dispH)+', format=BGRx ! videoconvert ! video/x-raw, format=BGR ! appsink'\n",
    "cap= cv2.VideoCapture(camSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6530cb16254e77920d48056b1ed411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 创建显示识别结果的控件区域\n",
    "face_imge2 = widgets.Image(format='jpeg', width=640, height=480)\n",
    "display(face_imge2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Video_display():\n",
    "    while True:      \n",
    "        ret, img = cap.read()\n",
    "        testImage = img.copy()  \n",
    "        facePositions=face_recognition.face_locations(testImage)\n",
    "        allEncodings=face_recognition.face_encodings(testImage,facePositions)       \n",
    "        for (top,right,bottom,left),face_encoding in zip(facePositions,allEncodings):\n",
    "            name='Unknown Person'\n",
    "            matches=face_recognition.compare_faces(Encodings,face_encoding)\n",
    "            if True in matches:\n",
    "                first_match_index=matches.index(True)\n",
    "                name=Names[first_match_index]\n",
    "            # 画框\n",
    "            cv2.rectangle(testImage,(left,top),(right,bottom),(0,0,255),2)\n",
    "            # 写人脸对应的name到图片\n",
    "            cv2.putText(testImage,name,(left,top-6),font,.75,(0,255,255),2)\n",
    "        face_imge2.value = bgr8_to_jpeg(testImage)\n",
    "\n",
    "    cap.release()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-10-423e7c42211e>\", line 4, in Video_display\n",
      "    testImage = img.copy()\n",
      "AttributeError: 'NoneType' object has no attribute 'copy'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t = threading.Thread(target=Video_display)\n",
    "t.setDaemon(True)\n",
    "t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid thread id",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-acaaca5ab484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 结束线程任务\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstop_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-dc49e736b601>\u001b[0m in \u001b[0;36mstop_thread\u001b[0;34m(thread)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstop_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0m_async_raise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-dc49e736b601>\u001b[0m in \u001b[0;36m_async_raise\u001b[0;34m(tid, exctype)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyThreadState_SetAsyncExc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexctype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid thread id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpythonapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyThreadState_SetAsyncExc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid thread id"
     ]
    }
   ],
   "source": [
    "# 结束线程任务\n",
    "stop_thread(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
